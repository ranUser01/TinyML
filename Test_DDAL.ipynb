{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn import tree\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from DDAL.ddal import DDAL_detector\n",
    "from DataFrame_batcher.batcher import BatchGenerator\n",
    "\n",
    "iris = load_iris()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iris: case from original repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x = pd.DataFrame(data= np.c_[iris['data'], iris['target']], columns= iris['feature_names'] + ['target']).sample(frac=1, random_state=42)\n",
    "df_y = df_x.pop('target')\n",
    "\n",
    "df_x_train = df_x[0:50]\n",
    "df_y_train = df_y[0:50]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = tree.DecisionTreeClassifier()\n",
    "classifier.fit(df_x_train, df_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddal = DDAL_detector(size_batch=50, theta=0.005, lambida=0.95)\n",
    "\n",
    "df_x_test_batch_1 = df_x[50:100]\n",
    "df_y_test_batch_1 = df_y[50:100].to_frame()\n",
    "\n",
    "df_x_test_batch_1.reset_index(inplace=True, drop=True)\n",
    "df_y_test_batch_1.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df_x_test_batch_1.iterrows():\n",
    "    y_pred = classifier.predict_proba(df_x_test_batch_1.iloc[[index]])\n",
    "    max_y_pred_prob = y_pred.max()\n",
    "    ddal.count_selected_instances(max_y_pred_prob)\n",
    "\n",
    "ddal.compute_current_density()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ddal.detection_module():\n",
    "    print('Drift Detected')\n",
    "    ddal.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sine test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "No drift detected\n",
      "No drift detected\n",
      "No drift detected\n",
      "No drift detected\n",
      "No drift detected\n",
      "No drift detected\n",
      "No drift detected\n",
      "No drift detected\n",
      "No drift detected\n",
      "No drift detected\n",
      "No drift detected\n",
      "No drift detected\n",
      "No drift detected\n",
      "No drift detected\n",
      "No drift detected\n",
      "No drift detected\n",
      "No drift detected\n",
      "No drift detected\n",
      "No drift detected\n",
      "No drift detected\n"
     ]
    }
   ],
   "source": [
    "data_sin = pd.read_csv(r'data\\tabular\\Sine.csv', index_col=0)\n",
    "data_sin['Classification'] = data_sin['Classification'].map({'Initially Negative':0,'Initially Positive':1})\n",
    "data_sin['Concept Drift'] = data_sin['Concept Drift'].map({'After Concept Drift Negative':0,'After Concept Drift Positive':1})\n",
    "\n",
    "data_sin_tmp = data_sin.copy()\n",
    "df_y = data_sin_tmp['Classification']\n",
    "\n",
    "training_proportion = int(2*len(data_sin)/5000)\n",
    "print(training_proportion)\n",
    "df_x_train = data_sin_tmp[0:training_proportion].drop(columns=['Concept Drift','Classification'])\n",
    "df_y_train = df_y[0:training_proportion]\n",
    "\n",
    "data_test = data_sin_tmp.iloc[training_proportion:len(data_sin_tmp)].reset_index(drop=True)\n",
    "classifier = tree.DecisionTreeClassifier()\n",
    "classifier.fit(df_x_train, df_y_train)\n",
    "y_out = np.ndarray([1,2])\n",
    "batcher = BatchGenerator(500,data_test)\n",
    "ddal = DDAL_detector(size_batch=500, theta=0.005, lambida=0.90)\n",
    "\n",
    "for batch_test in batcher:\n",
    "    batch_test = batch_test.drop(columns=['Concept Drift','Classification'])\n",
    "    for index,_ in batch_test.iterrows():\n",
    "        y_pred = classifier.predict_proba(batch_test.iloc[[index]])\n",
    "        y_out = np.concatenate((y_out,y_pred))\n",
    "        max_y_pred_prob = y_pred.max()\n",
    "        ddal.count_selected_instances(max_y_pred_prob)\n",
    "\n",
    "    ddal.compute_current_density()\n",
    "\n",
    "    if ddal.detection_module():\n",
    "        print('Drift Detected')\n",
    "        ddal.reset()\n",
    "        \n",
    "    else:\n",
    "        print('No drift detected')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.e+000, 1.e-323]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.13767619e-09, 3.23565722e-03],\n",
       "       [0.00000000e+00, 1.00000000e+00],\n",
       "       [1.00000000e+00, 0.00000000e+00],\n",
       "       ...,\n",
       "       [0.00000000e+00, 1.00000000e+00],\n",
       "       [0.00000000e+00, 1.00000000e+00],\n",
       "       [0.00000000e+00, 1.00000000e+00]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.808047852093529"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "preds = classifier.predict(data_test.drop(columns=['Concept Drift','Classification']))\n",
    "f1_score(data_test['Classification'],preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Very simple test\n",
    "\n",
    "just add scalar to values to change distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test['x'] = data_test['x'] + 1001241\n",
    "data_test['y'] = data_test['y'] - 19921341"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'DDAL' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m y_out \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray([\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m])\n\u001b[0;32m      2\u001b[0m batcher \u001b[38;5;241m=\u001b[39m BatchGenerator(\u001b[38;5;241m500\u001b[39m,data_test)\n\u001b[1;32m----> 3\u001b[0m ddal \u001b[38;5;241m=\u001b[39m DDAL(size_batch\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m500\u001b[39m, theta\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.005\u001b[39m, lambida\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.90\u001b[39m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_test \u001b[38;5;129;01min\u001b[39;00m batcher:\n\u001b[0;32m      6\u001b[0m     batch_test \u001b[38;5;241m=\u001b[39m batch_test\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mConcept Drift\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mClassification\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'DDAL' is not defined"
     ]
    }
   ],
   "source": [
    "y_out = np.ndarray([1,2])\n",
    "batcher = BatchGenerator(500,data_test)\n",
    "ddal = DDAL(size_batch=500, theta=0.005, lambida=0.90)\n",
    "\n",
    "for batch_test in batcher:\n",
    "    batch_test = batch_test.drop(columns=['Concept Drift','Classification'])\n",
    "    for index,_ in batch_test.iterrows():\n",
    "        y_pred = classifier.predict_proba(batch_test.iloc[[index]])\n",
    "        y_out = np.concatenate((y_out,y_pred))\n",
    "        max_y_pred_prob = y_pred.max()\n",
    "        ddal.count_selected_instances(max_y_pred_prob)\n",
    "\n",
    "    ddal.compute_current_density()\n",
    "\n",
    "    if ddal.detection_module():\n",
    "        print('Drift Detected')\n",
    "        ddal.reset()\n",
    "        \n",
    "    else:\n",
    "        print('No drift detected')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.e+000, 1.e-323],\n",
       "       [0.e+000, 1.e+000],\n",
       "       [0.e+000, 1.e+000],\n",
       "       ...,\n",
       "       [0.e+000, 1.e+000],\n",
       "       [0.e+000, 1.e+000],\n",
       "       [0.e+000, 1.e+000]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7791145038167939"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "preds = classifier.predict(data_test.drop(columns=['Concept Drift','Classification']))\n",
    "f1_score(data_test['Classification'],preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN\n",
    "\n",
    "same setup, but different classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No drift detected\n",
      "Drift Detected\n",
      "No drift detected\n",
      "No drift detected\n",
      "No drift detected\n",
      "No drift detected\n",
      "Drift Detected\n",
      "No drift detected\n",
      "No drift detected\n",
      "No drift detected\n",
      "No drift detected\n",
      "Drift Detected\n",
      "No drift detected\n",
      "No drift detected\n",
      "No drift detected\n",
      "No drift detected\n",
      "Drift Detected\n",
      "No drift detected\n",
      "No drift detected\n",
      "No drift detected\n"
     ]
    }
   ],
   "source": [
    "data_sin = pd.read_csv('../data/Sine.csv', index_col=0)\n",
    "data_sin['Classification'] = data_sin['Classification'].map({'Initially Negative':0,'Initially Positive':1})\n",
    "data_sin['Concept Drift'] = data_sin['Concept Drift'].map({'After Concept Drift Negative':0,'After Concept Drift Positive':1})\n",
    "\n",
    "data_sin_tmp = data_sin.copy()\n",
    "df_y = data_sin_tmp['Classification']\n",
    "\n",
    "training_proportion = int(2*len(data_sin)/100)\n",
    "print(training_proportion)\n",
    "df_x_train = data_sin_tmp[0:training_proportion].drop(columns=['Concept Drift','Classification'])\n",
    "df_y_train = df_y[0:training_proportion]\n",
    "\n",
    "data_test = data_sin_tmp.iloc[training_proportion:len(data_sin_tmp)].reset_index(drop=True)\n",
    "classifier = KNeighborsClassifier()\n",
    "classifier.fit(df_x_train, df_y_train)\n",
    "y_out = np.ndarray([1,2])\n",
    "batcher = BatchGenerator(500,data_test)\n",
    "ddal = DDAL(size_batch=500, theta=0.005, lambida=0.90)\n",
    "\n",
    "for batch_test in batcher:\n",
    "    batch_test = batch_test.drop(columns=['Concept Drift','Classification'])\n",
    "    for index,_ in batch_test.iterrows():\n",
    "        y_pred = classifier.predict_proba(batch_test.iloc[[index]])\n",
    "        y_out = np.concatenate((y_out,y_pred))\n",
    "        max_y_pred_prob = y_pred.max()\n",
    "        ddal.count_selected_instances(max_y_pred_prob)\n",
    "\n",
    "    ddal.compute_current_density()\n",
    "\n",
    "    if ddal.detection_module():\n",
    "        print('Drift Detected')\n",
    "        ddal.reset()\n",
    "        \n",
    "    else:\n",
    "        print('No drift detected')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_y_pred_prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mnist\n",
    "\n",
    "So far decision tree seems to be extremly confident in its predictions, even when it trains from two examples. On the other hand, not-fine tuned knn detects drift, when they are none. However, maybe training sample is too low"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DDAL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
