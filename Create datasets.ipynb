{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import manual_seed, tensor, nonzero, logical_not, load, save\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torch.utils.data import DataLoader, random_split, IterableDataset, Dataset, sampler\n",
    "from torchvision.transforms import Compose, ToTensor, Normalize, RandomRotation,Resize, Grayscale\n",
    "from torchvision.datasets.mnist import MNIST \n",
    "from torchshow import show\n",
    "from CNN_setup.model.CIFAR_CNN import CIFAR_CNN_Classifier\n",
    "from CNN_setup.vars.CIFARvars import CIFAR10_classes\n",
    "from CNN_setup.datasets.datasets import CustomCIFAR10, CustomMNIST\n",
    "\n",
    "from CNN_setup.model.MNIST_CNN import Mnist_CNN_Classifier\n",
    "from CNN_setup.vars.MNISTvars import MNIST_classes\n",
    "\n",
    "from CNN_setup.utils.cnn_models_utils import load_model, evaluate\n",
    "\n",
    "from PIL import Image\n",
    "from torchshow import show\n",
    "\n",
    "from CNN_setup.datasets.dataset_tools import save_dataset, combine_datasets\n",
    "\n",
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "from torch.utils.data import ConcatDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Incremental, abrupt, and transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = Compose([ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_dataset = CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "test_dataset = CIFAR10(root='./data', train=False, download=False, transform=transform)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Withhold a class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "raw_data = CIFAR10(root='./data', train=False, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dataset(path='data/transformed/cifar-rotated90', data=raw_data, transform=Image.Image.rotate, args=(90,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m save_dataset(path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/transformed/cifar-wo-0\u001b[39m\u001b[38;5;124m'\u001b[39m, data\u001b[38;5;241m=\u001b[39mraw_data)\n",
      "File \u001b[1;32mc:\\Users\\wilkk\\OneDrive - ITU\\3rd year\\TinyML\\CNN_setup\\datasets\\dataset_tools.py:21\u001b[0m, in \u001b[0;36msave_dataset\u001b[1;34m(data, path, transform, args)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, (img, label) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(data):\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;66;03m# Apply the transformation if one was provided\u001b[39;00m\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m transform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 21\u001b[0m         img \u001b[38;5;241m=\u001b[39m transform(img,  \u001b[38;5;241m*\u001b[39margs)\n\u001b[0;32m     22\u001b[0m     os\u001b[38;5;241m.\u001b[39mmakedirs(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     23\u001b[0m     img\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/img_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.png\u001b[39m\u001b[38;5;124m'\u001b[39m,)\n",
      "File \u001b[1;32m<frozen os>:213\u001b[0m, in \u001b[0;36mmakedirs\u001b[1;34m(name, mode, exist_ok)\u001b[0m\n",
      "File \u001b[1;32m<frozen genericpath>:19\u001b[0m, in \u001b[0;36mexists\u001b[1;34m(path)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "save_dataset(path='data/transformed/cifar-wo-0', data=raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "rotated = ImageFolder(root='data/transformed/cifar-rotated90', transform=ToTensor())\n",
    "dataloader_rotated = DataLoader(dataset=rotated, batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('trained_models\\CNN_cifar_downloaded.torch', CIFAR_CNN_Classifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for class: plane is 40.5 %\n",
      "Accuracy for class: car is 1.0 %\n",
      "Accuracy for class: bird is 9.4 %\n",
      "Accuracy for class: cat is 8.9 %\n",
      "Accuracy for class: deer is 68.9 %\n",
      "Accuracy for class: dog is 3.1 %\n",
      "Accuracy for class: frog is 11.8 %\n",
      "Accuracy for class: horse is 0.7 %\n",
      "Accuracy for class: ship is 18.8 %\n",
      "Accuracy for class: truck is 12.2 %\n",
      "Total Accuracy: 17.5 %\n"
     ]
    }
   ],
   "source": [
    "evaluate(model=model, test_dataloader=dataloader_rotated, classes=CIFAR10_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check MNIST rotate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_rotate = Compose([ToTensor(), RandomRotation(degrees=(90,90))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_mnist = MNIST(root='./data', train=False, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dataset(path='data/transformed/mnist-rotated90', data=raw_data_mnist, transform=Image.Image.rotate, args=(90,))\n",
    "save_dataset(path='data/transformed/mnist-wo-0', data=raw_data_mnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CustomerMnist_obj = CustomMNIST(root='./data', train=True, download=True, transform=transform_rotate) ## Another way of creating fully rotated dataset\n",
    "# CustomerMnist_obj_dataloader = DataLoader(CustomerMnist_obj, batch_size=32)\n",
    "\n",
    "MNIST_model = load_model(\"trained_models/CNN_mnist_downloaded.torch\",Mnist_CNN_Classifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rotated_mnist = ImageFolder(root='data/transformed/mnist-rotated90', transform=Compose([ToTensor(),Grayscale(num_output_channels=1)]))\n",
    "dataloader_rotated_mnist = DataLoader(dataset=rotated_mnist, batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for class: 0 is 56.0 %\n",
      "Accuracy for class: 1 is 0.8 %\n",
      "Accuracy for class: 2 is 21.0 %\n",
      "Accuracy for class: 3 is 0.7 %\n",
      "Accuracy for class: 4 is 9.4 %\n",
      "Accuracy for class: 5 is 8.3 %\n",
      "Accuracy for class: 6 is 15.6 %\n",
      "Accuracy for class: 7 is 9.0 %\n",
      "Accuracy for class: 8 is 10.2 %\n",
      "Accuracy for class: 9 is 16.7 %\n",
      "Total Accuracy: 14.6 %\n"
     ]
    }
   ],
   "source": [
    "evaluate(dataloader_rotated_mnist,MNIST_model,classes = MNIST_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Incremental"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, Subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataset.ConcatDataset at 0x26f3ea01550>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def combine_datasets(dataset1:Dataset, dataset2:Dataset, proportion1:float):\n",
    "    assert 1 >= proportion1 > 0 \n",
    "    proportion2 = 1 - proportion1\n",
    "    # Calculate the total number of samples based on the proportions\n",
    "    total_samples = int((len(dataset1) * proportion1) + (len(dataset2) * proportion2))\n",
    "\n",
    "    # Calculate the number of samples to take from each dataset\n",
    "    threshold1 = int(total_samples * proportion1)\n",
    "    threshold2 = int(total_samples * proportion2)\n",
    "\n",
    "    # Take the first 'threshold' samples from each dataset\n",
    "    subset1 = Subset(dataset1, range(threshold1))\n",
    "    subset2 = Subset(dataset2, range(threshold2))\n",
    "    \n",
    "    # Combine the two datasets\n",
    "    combined_data = ConcatDataset([subset1, subset2])\n",
    "    \n",
    "    return combined_data\n",
    "\n",
    "x = combine_datasets(rotated,raw_data,proportion1=1)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i, l in x:\n",
    "    break\n",
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Drift_image_test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
